<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>hive.metastore.uris</name>
    <value>thrift://hadoop01:9083</value>
  </property>

  <property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/user/hive/warehouse</value>
  </property>

  <property>
      <name>javax.jdo.option.ConnectionURL</name>
      <value>jdbc:mysql://hadoop01:3306/hive?createDatabaseIfNotExist=true&amp;characterEncoding=UTF-8</value>
  </property>

  <property>
      <name>javax.jdo.option.ConnectionDriverName</name>
      <value>com.mysql.jdbc.Driver</value>
  </property>

  <property>
      <name>javax.jdo.option.ConnectionUserName</name>
      <value>root</value>
  </property>

  <property>
      <name>javax.jdo.option.ConnectionPassword</name>
      <value>root</value>
  </property>

  <property>
      <name>hive.exec.scratchdir</name>
      <value>/tmp/hivescratchdir/hive-${user.name}</value>
      <description>HDFS root scratch dir for Hive jobs which gets created with write all (733) permission. For each connecting user, an HDFS scratch dir: ${hive.exec.scratchdir}/&lt;username&gt; is created, with ${hive.scratch.dir.permission}.</description>
  </property>

  <property>
      <name>hive.exec.parallel</name>
      <value>true</value>
      <description>Whether to execute jobs in parallel</description>
  </property>

  <property>
      <name>hive.exec.parallel.thread.number</name>
      <value>16</value>
      <description>How many jobs at most can be executed in parallel</description>
  </property>

  <property>
      <name>hive.exec.compress.output</name>
      <value>true</value>
      <description>
        This controls whether the final outputs of a query (to a local/HDFS file or a Hive table) is compressed.
        The compression codec and other options are determined from Hadoop config variables mapred.output.compress*
      </description>
  </property>

  <property>
      <name>hive.mapred.local.mem</name>
      <value>1024</value>
      <description>mapper/reducer memory in local mode</description>
  </property>

  <property>
      <name>io.sort.mb</name>
      <value>100</value>
  </property>

  <property>
      <name>hive.cli.print.header</name>
      <value>true</value>
      <description>Whether to print the names of the columns in query output.</description>
  </property>

  <property>
      <name>hive.cli.print.current.db</name>
      <value>true</value>
      <description>Whether to include the current database in the Hive prompt.</description>
  </property>

  <property>
      <name>hive.exec.mode.local.auto</name>
      <value>false</value>
      <description>Let Hive determine whether to run in local mode automatically</description>
  </property>

  <property>
      <name>hive.auto.convert.join</name>
      <value>true</value>
      <description>Whether Hive enables the optimization about converting common join into mapjoin based on the input file size</description>
  </property>

  <property>
      <name>hive.mapjoin.smalltable.filesize</name>
      <value>25000000</value>
      <description>
        The threshold for the input file size of the small tables; if the file size is smaller
        than this threshold, it will try to convert the common join into map join
      </description>
  </property>

  <property>
      <name>hive.exec.dynamic.partition</name>
      <value>true</value>
      <description>Whether or not to allow dynamic partitions in DML/DDL.</description>
  </property>

  <property>
      <name>hive.exec.dynamic.partition.mode</name>
      <value>strict</value>
      <description>
        In strict mode, the user must specify at least one static partition
        in case the user accidentally overwrites all partitions.
        In nonstrict mode all partitions are allowed to be dynamic.
      </description>
  </property>

  <property>
      <name>hive.exec.max.dynamic.partitions.pernode</name>
      <value>1000</value>
      <description>Maximum number of dynamic partitions allowed to be created in each mapper/reducer node.</description>
  </property>

  <property>
      <name>hive.mapred.mode</name>
      <value>nostrict</value>
  </property>

  <property>

      <name>hive.server2.thrift.port</name>
      <value>10000</value>
  </property>

  <property>
      <name>hive.server2.thrift.bind.host</name>
      <value>hadoop01</value>
  </property>

  <property>
      <name>hive.support.concurrency</name>
      <value>true</value>
      <description>
        Whether Hive supports concurrency control or not.
        A ZooKeeper instance must be up and running when using zookeeper Hive lock manager
      </description>
  </property>

  <property>
      <name>hive.zookeeper.quorum</name>
      <value>hadoop01</value>
      <description>
        List of ZooKeeper servers to talk to. This is needed for:
        1. Read/write locks - when hive.lock.manager is set to
        org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager,
        2. When HiveServer2 supports service discovery via Zookeeper.
        3. For delegation token storage if zookeeper store is used, if
        hive.cluster.delegation.token.store.zookeeper.connectString is not set
        4. LLAP daemon registry service
      </description>
  </property>

  <property>
      <name>hive.zookeeper.client.port</name>
      <value>2181</value>
      <description>
        The port of ZooKeeper servers to talk to.
        If the list of Zookeeper servers specified in hive.zookeeper.quorum
        does not contain port numbers, this value is used.
      </description>
  </property>

  <property>
      <name>hive.aux.jars.path</name>
      <value></value>
      <description>The location of the plugin jars that contain implementations of user defined functions and serdes.</description>
  </property>

  <property>
      <name>hive.execution.engine</name>
      <value>tez</value>
      <description>
        Expects one of [mr, tez, spark].
        Chooses execution engine. Options are: mr (Map reduce, default), tez, spark. While MR
        remains the default engine for historical reasons, it is itself a historical  engine
        and is deprecated in Hive 2 line. It may be removed without further warning.
      </description>
  </property>

  <property>
    <name>hive.tez.container.size</name>
    <value>1024</value>
  </property>

  <property>
      <name>hive.server2.global.init.file.location</name>
      <value>$HIVE_HOME/conf</value>
      <description>
        Either the location of a HS2 global init file or a directory containing a .hiverc file. If the
        property is set, the value must be a valid path to an init file or directory where the init file is located.
      </description>
  </property>
  
  <property>
    <name>hive.server2.enable.doAs</name>
    <value>false</value>
    <description>
      Setting this property to true will have HiveServer2 execute
      Hive operations as the user making the calls to it.
    </description>
  </property>

  <property>
    <name>hive.metastore.schema.verification</name>
    <value>false</value>
    <description>
      Enforce metastore schema version consistency.
      True: Verify that version information stored in is compatible with one from Hive jars.  Also disable automatic
        schema migration attempt. Users are required to manually migrate schema after Hive upgrade which ensures
        proper metastore schema migration. (Default)
      False: Warn if the version information stored in metastore doesn't match with one from in Hive jars.
    </description>
  </property>

</configuration>
